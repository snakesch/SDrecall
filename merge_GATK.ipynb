{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3382e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook implements the last step in SDrecall to merge GATK variants with SDrecall variants.\n",
    "\n",
    "# -- Required user-defined parameters -- # \n",
    "# 1. VCF generated with SDrecall\n",
    "# 2. VCF generated with other algorithms (eg. GATK)\n",
    "# 3. Sample ID (usually sample name) \n",
    "# 4. PED file of samples\n",
    "\n",
    "# -- Main steps -- #\n",
    "# A. Check if SDrecall VCF contains > 10 variants\n",
    "# B. Make sure SDrecall VCF is in diploidy format\n",
    "# C. Merge variants with priority\n",
    "#  > Usage: merge_variants_with_priority.py -ov {SDrecall VCF} -pv {GATK VCF} -op {sample_ID.merged.vcf.gz}\n",
    "# D. Output VCF should have > 10000 variants \n",
    "# E. Mark homoseq recall shortv & tabix indexing\n",
    "\n",
    "# -- Ideas -- #\n",
    "# 1. Create a class \"Variant\"\n",
    "# 2. Version sort for chromosome order https://stackoverflow.com/questions/2574080/sorting-a-list-of-dot-separated-numbers-like-software-versions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d79304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from src.utils import *\n",
    "from pandarallel import pandarallel as pa\n",
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "ov_vcf = \"/home/louisshe/shortVariantVCF/data/merge_vcfs/PID21-055.homo_region.filtered.vcf.gz\"\n",
    "pv_vcf = \"/home/louisshe/shortVariantVCF/data/merge_vcfs/PID21-055.gatk.g.vcf.gz.chr13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729689a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variant:\n",
    "    \"\"\"\n",
    "    This class creates a Variant object for each record in a graph.\n",
    "    \n",
    "    This is designated for VCFs with one sample.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    def __init__(self, row, idx):\n",
    "        \n",
    "        \"\"\"\n",
    "        Variant constructor based on a pandas dataframe\n",
    "        \n",
    "        Note:\n",
    "        -------\n",
    "        Rows should be taken from a dataframe sorted by chromosome (chrM, chr1, ..., chrX, chrY), or by the order in fai file\n",
    "        \n",
    "        Error:\n",
    "        -------\n",
    "        KeyError: No INSLEN in INS records\n",
    "        ValueError: No sample calls\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.CHROM = row[\"#CHROM\"]\n",
    "        self.START = int(row[\"POS\"])\n",
    "        self.ID = row[\"ID\"]\n",
    "        self.FILTER = row[\"FILTER\"]\n",
    "        self.QUAL = row[\"QUAL\"]\n",
    "        self.REF = row[\"REF\"]\n",
    "        self.ALT = row[\"ALT\"].split(\",\")[0] # Only consider the biallelic case\n",
    "        self.idx = int(row[\"POS\"])\n",
    "        \n",
    "        # Data from INFO field\n",
    "        self._INFO = {field.split(\"=\")[0]: field.split(\"=\")[1:] for field in row[\"INFO\"].split(\";\")}\n",
    "        self.END = int(self._INFO[\"END\"][0]) if \"END\" in self._INFO.keys() else row[\"POS\"]\n",
    "        self.VARTYPE = self._INFO[\"SVTYPE\"][0] if \"SVTYPE\" in self._INFO.keys() else \"short_variant\"\n",
    "        if self.VARTYPE == \"INS\":\n",
    "            try:\n",
    "                self.INSEND = self.START + int(self._INFO[\"INSLEN\"][0])\n",
    "            except KeyError:\n",
    "                raise KeyError(f\"No INSLEN field in INS variant.\\n{row} \")\n",
    "            self.INSSEQ = self._INFO[\"INSSEQ\"] if \"INSSEQ\" in self._INFO.keys() else \"N\"\n",
    "        \n",
    "        # Data from sample field\n",
    "        if row.shape[0] - 9 > 1:\n",
    "            logging.warning(f\"Multiple samples found. Only consider the first sample. \")\n",
    "        elif row.shape[0] == 9:\n",
    "            raise ValueError(f\"No sample found in the given VCF for the variants.\\n{self.__repr__()}\")        \n",
    "        \n",
    "        _sample = [row[\"FORMAT\"].split(\":\")] + [row[col].split(\":\") for col in range(9, row.shape[0], 1)]\n",
    "        self.SAMPLE = {sample[0]: sample[1] for sample in zip(*_sample)}\n",
    "        try:\n",
    "            self.DP = float(self.SAMPLE[\"DP\"])\n",
    "        except (KeyError, TypeError): # Case: DP not available or DP = \".\"\n",
    "            self.DP = \".\"\n",
    "        \n",
    "        try:\n",
    "            self.GT = self.SAMPLE[\"GT\"] if self.DP != \".\" and self.DP != 0.0 else \".\"\n",
    "        except:\n",
    "            raise KeyError(f\"GT not found in the variant:\\n{self.__repr__()}\")\n",
    "        \n",
    "        self.MISSING_GT = (self.GT == \"./.\") or (self.GT == \".|.\") or (self.GT == \".\")\n",
    "            \n",
    "        if \"AD\" in self.SAMPLE.keys():\n",
    "            self.AD = list(map(int, self.SAMPLE[\"AD\"].split(\",\")))\n",
    "            if self.AD[0] > 0 and self.AD == 0:\n",
    "                self.GT = \"0\"\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        String representation of the variant.\n",
    "        \"\"\"\n",
    "        return f\"{self.CHROM}:{self.START}-{self.END} {self.REF}>{self.ALT}\\nType: {self.VARTYPE}\\nGenotype: {self.GT}\\nSample: {self.SAMPLE}\"\n",
    "    \n",
    "    def getSeries(self):\n",
    "\n",
    "        keys = [\"#CHROM\", \"POS\", \"ID\", \"REF\", \"ALT\", \"QUAL\", \"FILTER\", \"INFO\", \"FORMAT\", row.index[9]]\n",
    "        try:\n",
    "            values = [self.CHROM, self.START, self.ID, self.REF, self.ALT, self.QUAL, self.FILTER, \n",
    "                 \";\".join([f\"{key}={value[0]}\" for key, value in self._INFO.items()]),\n",
    "                 \":\".join(self.SAMPLE.keys()),\n",
    "                 \":\".join(self.SAMPLE.values())]\n",
    "        except:\n",
    "            values = [self.CHROM, self.START, self.ID, self.REF, self.ALT, self.QUAL, self.FILTER, \n",
    "                 \".\",\n",
    "                 \":\".join(self.SAMPLE.keys()),\n",
    "                 \":\".join(self.SAMPLE.values())]\n",
    "\n",
    "        return pd.Series(values, index=keys)\n",
    "    \n",
    "    def addFilter(self, *tag):\n",
    "        \n",
    "        tags = list(tag)\n",
    "        if self.FILTER == \"PASS\":\n",
    "            self.FILTER = \";\".join(tags)\n",
    "        else:\n",
    "            of = self.FILTER.split(\";\") + tags\n",
    "            self.FILTER = \";\".join(of)     \n",
    "    \n",
    "    def isAdjacent(self, other):\n",
    "        \n",
    "        s_thresh = 1\n",
    "        \n",
    "        if self == other:\n",
    "            return True\n",
    "        else:\n",
    "            l, r = sorted([self, other])\n",
    "            return (r.START - l.END <= s_thresh)     \n",
    "    \n",
    "    def overlap_fraction(self, other):\n",
    "        \n",
    "        l, r = sorted([self, other])\n",
    "        if r.START < l.END:\n",
    "            return abs((r.START - l.END) / (r.END - l.START))\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        f_thresh = 0.95\n",
    "        \n",
    "        if (self.VARTYPE != other.VARTYPE) or (self.CHROM != other.CHROM):\n",
    "            return False\n",
    "        elif self.VARTYPE == other.VARTYPE == \"short_variant\":\n",
    "            return (self.START == other.START) and (self.END == other.END) \\\n",
    "                    and (self.REF == other.REF) and (self.ALT == other.ALT)\n",
    "        elif self.VARTYPE == other.VARTYPE == \"BND\":\n",
    "            return self.isAdjacent(other)\n",
    "        else:\n",
    "            if self.VARTYPE != \"INS\":\n",
    "                return (self.overlap_fraction(other) >= f_thresh)\n",
    "            elif not self.isAdjacent(other):\n",
    "                return False\n",
    "            else:\n",
    "                ofrac = self.overlap_fraction(other)\n",
    "                if ofrac == 0.0:\n",
    "                    return False\n",
    "                elif self.INSSEQ != \"N\" and other.INSSEQ != \"N\":\n",
    "                    seqsim = SequenceMatcher(None, self.INSSEQ, other.INSSEQ).ratio()\n",
    "                    return (seqsim >= f_thresh)\n",
    "                else:\n",
    "                    return (ofrac >= f_thresh)\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not (self == other)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.idx < other.idx\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.idx <= other.idx\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.idx > other.idx\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self.idx >= other.idx\n",
    "\n",
    "def bsearch(var, low, high, x) -> tuple:\n",
    "    \"\"\"\n",
    "    Binary search function for finding SDrecall variants.\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    Found: Variant object, index of the object\n",
    "    Not found: None\n",
    "    \n",
    "    \"\"\"\n",
    "    if high >= low:\n",
    "        mid = (high + low) // 2\n",
    "        if var[mid] == x:\n",
    "            return var[mid], mid\n",
    "        elif var[mid] > x:\n",
    "            return bsearch(var, low, mid - 1, x)\n",
    "        else:\n",
    "            return bsearch(var, mid + 1, high, x)\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def pick_rep_rec(row, ov_vars, pv_tag, ov_tag) -> pd.Series:\n",
    "    \"\"\"\n",
    "    This function processes variants which are found in both VCFs.\n",
    "    \"\"\"  \n",
    "    pv_var = Variant(row, row.name)\n",
    "    ov_var, idx = bsearch(ov_vars, 0, len(ov_vars) - 1, pv_var)\n",
    "    if ov_var:\n",
    "        dup_ov_vars.append(idx) # Keep indices of found items\n",
    "        if pv_var.GT == ov_var.GT:\n",
    "            pv_var.addFilter(ov_tag, pv_tag)\n",
    "            return pv_var.getSeries()\n",
    "        elif \"0\" in pv_var.GT or \".\" in pv_var.GT:\n",
    "            ov_var.addFilter(ov_tag, pv_tag)\n",
    "            return ov_var.getSeries()\n",
    "        elif \"0\" in ov_var.GT or \".\" in ov_var.GT:\n",
    "            pv_var.addFilter(ov_tag, pv_tag)\n",
    "            return pv_var.getSeries()\n",
    "        else:\n",
    "            pv_var.addFilter(ov_tag, pv_tag)\n",
    "            return pv_var.getSeries()\n",
    "    else: # Not found in SDrecall VCF\n",
    "        if \"0\" in pv_var.GT or \".\" in pv_var.GT:\n",
    "            return None\n",
    "        else:\n",
    "            pv_var.addFilter(pv_tag)\n",
    "            return pv_var.getSeries()\n",
    "        \n",
    "def concat_headers(header_1, header_2) -> list[str]:\n",
    "    \"\"\"\n",
    "    This function takes two VCF headers and returns a merged header. \n",
    "    \"\"\"\n",
    "    # Get original order\n",
    "    fields = [ field.split(\"=\")[0].strip(\"#\") for field in header_1 ] + [ field.split(\"=\")[0].strip(\"#\") for field in header_2 ]\n",
    "    _unique_fields = list(dict.fromkeys(fields))\n",
    "    order = dict(zip(_unique_fields, range(len(_unique_fields))))\n",
    "    \n",
    "    # Merge headers  \n",
    "    merged_header = sorted(list(set(header_1 + header_2)), key=lambda x: order[x.split(\"=\")[0].strip(\"#\")])\n",
    "    \n",
    "    return merged_header\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb8ee5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f053ce088c25443a9aac786271696eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=17), Label(value='0 / 17'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processed 500000 variants. \n"
     ]
    }
   ],
   "source": [
    "def merge(pv_vcf, ov_vcf, pv_tag, ov_tag):\n",
    "    \"\"\"\n",
    "    This function merges prioritized VCF with original VCF on a chromosome-wise basis.\n",
    "    \"\"\"\n",
    "    ov_header, ov_subjects, ov_df = loadVCF(ov_vcf)\n",
    "    pv_header, pv_subjects = loadVCF(pv_vcf, omit_record=True)\n",
    "\n",
    "    # Get chromosome number\n",
    "    chrom = pv_vcf.split(\".\")[-1]\n",
    "    logging.info(f\"Processing chromosome {chrom} ... \")\n",
    "    \n",
    "    # Prepare ov variants\n",
    "    ov_vars = []\n",
    "    dup_ov_vars = []\n",
    "    for idx, row in ov_df[ov_df[\"#CHROM\"] == chrom].iterrows():\n",
    "        ov_vars.append(Variant(row, idx))\n",
    "    ov_vars = sorted(ov_vars)\n",
    "\n",
    "    header = ov_df.columns\n",
    "    processed = 0\n",
    "    from_pv = pd.DataFrame()\n",
    "    with pd.read_csv(pv_vcf, sep=\"\\t\", na_filter=False, engine=\"c\", \n",
    "                     comment=\"#\", header=None, names=header, compression=\"gzip\", \n",
    "                     skiprows=32959110, chunksize=500000) as reader:\n",
    "        for pv_chunk in reader:\n",
    "            processed += 500000\n",
    "            from_pv_tmp = pv_chunk.parallel_apply(pick_rep_rec, axis=1, args=(ov_vars, pv_tag, ov_tag,)).dropna()\n",
    "            if from_pv_tmp.shape[0] != 0:\n",
    "                from_pv = pd.concat([from_pv, from_pv_tmp], axis=0)\n",
    "            logging.info(f\"Processed {processed} variants. \")\n",
    "\n",
    "    from_ov = ov_df[~ov_df.index.isin(dup_ov_vars)]\n",
    "    pv_ov = pd.concat([from_pv, from_ov], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return pv_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92b20854-b5ee-4506-ae9d-c797be933184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge head\n",
    "ov_vcf = \"/home/louisshe/shortVariantVCF/data/merge_vcfs/PID21-055.homo_region.filtered.vcf.gz\"\n",
    "pvcf = \"/home/louisshe/shortVariantVCF/data/merge_vcfs/PID21-055.gatk.g.vcf.gz\"\n",
    "workers = 8\n",
    "pv_tag = \"GATK\"\n",
    "ov_tag = \"SDrecall\"\n",
    "\n",
    "def main(pvcf, ov_vcf, outpath, pv_tag, ov_tag, workers):\n",
    "    \"\"\"\n",
    "    Main function for merging prioritized variants and original variants.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    pvcf: Prioritized VCF holding variants from all contigs\n",
    "    ov_vcf: Original VCF (eg. VCF from SDrecall)\n",
    "    ov_tag: tag used for variants called from ov_vcf\n",
    "    pv_tag: tag used for variants called from pvcf\n",
    "    outpath: absolute path of output VCF (gzipped)\n",
    "    workers: number of cores to use\n",
    "        \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    # Load prioritized VCF and original VCF (as file streams)\n",
    "    os.chdir(os.path.dirname(pvcf))\n",
    "    os.makedirs(\"tmp\", exist_ok=True)\n",
    "\n",
    "    ov_header, ov_subjects, ov_df = loadVCF(ov_vcf)\n",
    "    pv_header, pv_subjects = loadVCF(pv_vcf, omit_record=True)\n",
    "    all_chr = [ pcontig[13:].split(\",\")[0] for pcontig in pv_header if pcontig.startswith(\"##contig\") ]\n",
    "\n",
    "    for contig in all_chr:\n",
    "        cmd = f\"bcftools filter -r {contig} -Oz -o {os.path.join('tmp/', os.path.basename(pvcf) + '.') + str(contig)} {pvcf} \"\n",
    "        executeCmd(cmd)\n",
    "    logging.info(f\"****************** VCF splitting completed in {time.time() - start:.2f} seconds ******************\")\n",
    "        \n",
    "    os.chdir(\"tmp/\") # Descend into tmp/\n",
    "    pv_vcfs = [pv_vcf for pv_vcf in os.listdir()]\n",
    "\n",
    "    # Write new VCF header\n",
    "    ov_filter_head = f\"##FILTER=<ID={ov_tag},Description='variants called from {ov_tag}'>\"\n",
    "    pv_filter_head = f\"##FILTER=<ID={pv_tag},Description='variants called from {pv_tag}'>\"\n",
    "    ov_header.append(ov_filter_head)\n",
    "    ov_header.append(pv_filter_head)\n",
    "    merged_header = concat_headers(pv_header, ov_header)\n",
    "    with gzip.open(outpath) as f:\n",
    "        f.write(\"\\n\".join(merged_header).encode())\n",
    "        f.write(\"\\n\".encode())\n",
    "        f.write(\"\\t\".join(ov_df.columns.tolist()).encode())\n",
    "        f.write(\"\\n\".encode())\n",
    "\n",
    "    # Process prioritized variants\n",
    "    pa.initialize(progress_bar=False, verbose=0, nb_workers=workers)\n",
    "\n",
    "    for pv_vcf in pv_vcfs:\n",
    "        merged_df = merge(pv_vcf, ov_vcf, pv_tag, ov_tag)\n",
    "        merged_df.to_csv(outpath, sep=\"\\t\", index=False, header=False, mode=\"a\", compression=\"gzip\")\n",
    "\n",
    "    # Cleanup\n",
    "    os.chdir(os.path.dirname(pvcf))\n",
    "    os.remove(\"tmp/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Argparse setup\n",
    "    parser = argparse.ArgumentParser(description = \"Merge prioritized VCF and original VCF.\")\n",
    "    parser._optionals.title = \"Options\"\n",
    "    ROOT = os.path.dirname(__file__)\n",
    "    parser.add_argument(\"--pvcf\", type = str, help = \"prioritized VCF (gz)\", required = True)\n",
    "    parser.add_argument(\"--ovcf\", type = str, help = \"original VCF (gz)\", required = True)\n",
    "    parser.add_argument(\"--pv_tag\", type = str, help = \"tag used for variants from prioritized VCF\", required = True)\n",
    "    parser.add_argument(\"--ov_tag\", type = str, help = \"tag used for variants from original VCF\", required = True)\n",
    "    parser.add_argument(\"--outpath\", type = str, help = \"absolute output path of merged VCF (gz)\", required = True)\n",
    "    parser.add_argument(\"--thread\", type = int, help = \"number of threads (default: 8)\", default = 8)\n",
    "    parser.add_argument(\"-v\", \"--verbose\", type = str, default = \"INFO\", help = \"verbosity level (default: INFO)\")\n",
    "    args = parser.parse_args()\n",
    "    logging.basicConfig(format='[%(asctime)s] %(levelname)s: %(message)s', datefmt='%a %b-%m %I:%M:%S%P',\n",
    "                        level = args.verbose.upper())\n",
    "    logging.debug(f\"Working in {ROOT}\")  \n",
    "    \n",
    "    main(args.pvcf, args.ovcf, args.outpath, args.pv_tag, args.ov_tag, args.thread)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "09afae35-15f7-40c9-8c7e-1abce866bf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['##fileformat=VCFv4.2',\n",
       " '##FILTER=<ID=PASS,Description=\"All filters passed\">',\n",
       " '##FILTER=<ID=LIKELY_INTRINSIC,Description=\"The variant called is likely due to intrinsic difference between homologous sequences in the ref genome.\">',\n",
       " '##FILTER=<ID=LowQual,Description=\"Low quality\">',\n",
       " '##FILTER=<ID=UNLIKELY_INTRINSIC,Description=\"The variant called is unlikely due to intrinsic difference between homologous sequences in the ref genome. ALT/REF ratio is higher than theoretical value for wildtype.\">',\n",
       " '##ALT=<ID=NON_REF,Description=\"Represents any possible alternative allele not already represented at this location by REF and ALT\">',\n",
       " '##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\"Genotype Quality\">',\n",
       " '##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=\"Minimum DP observed within the GVCF block\">',\n",
       " '##FORMAT=<ID=PGT,Number=1,Type=String,Description=\"Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another; will always be heterozygous and is not intended to describe called alleles\">',\n",
       " '##FORMAT=<ID=RGQ,Number=1,Type=Integer,Description=\"Unconditional reference genotype confidence, encoded as a phred quality -10*log10 p(genotype call is wrong)\">',\n",
       " '##FORMAT=<ID=PID,Number=1,Type=String,Description=\"Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group\">',\n",
       " '##FORMAT=<ID=PS,Number=1,Type=Integer,Description=\"Phasing set (typically the position of the first variant in the set)\">',\n",
       " '##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">',\n",
       " '##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification\">',\n",
       " '##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">',\n",
       " '##FORMAT=<ID=SB,Number=4,Type=Integer,Description=\"Per-sample component statistics which comprise the Fisher\\'s Exact Test to detect strand bias.\">',\n",
       " '##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">',\n",
       " '##GATKCommandLine=<ID=LeftAlignAndTrimVariants,CommandLine=\"LeftAlignAndTrimVariants --output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ALPI.tmp.vcf.gz --dont-trim-alleles true --split-multi-allelics true --max-indel-length 2000 --max-leading-bases 2000 --variant /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ALPI.vcf.gz --reference /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --keep-original-ac false --suppress-reference-path false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false\",Version=\"4.2.6.1\",Date=\"August 20, 2022 at 8:26:43 PM HKT\">',\n",
       " '##GATKCommandLine=<ID=HaplotypeCaller,CommandLine=\"HaplotypeCaller --linked-de-bruijn-graph true --bam-output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.chrM.realigned.bam --bam-writer-type CALLED_HAPLOTYPES --emit-ref-confidence GVCF --output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/gvcfs/PID21-055.chrM.HC.g.vcf.gz --active-probability-threshold 0.0012 --assembly-region-padding 100 --assembly-region-out /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/gvcfs/PID21-055.chrM.HC.active_region.tsv --intervals chrM --input /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.bqsr.bam --reference /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --create-output-bam-index true --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --annotation-group StandardHCAnnotation --use-posteriors-to-calculate-qual false --dont-use-dragstr-priors false --use-new-qual-calculator true --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genotype-assignment-method USE_PLS_TO_ASSIGN --contamination-fraction-to-filter 0.0 --output-mode EMIT_VARIANTS_ONLY --all-site-pls false --gvcf-gq-bands 1 --gvcf-gq-bands 2 --gvcf-gq-bands 3 --gvcf-gq-bands 4 --gvcf-gq-bands 5 --gvcf-gq-bands 6 --gvcf-gq-bands 7 --gvcf-gq-bands 8 --gvcf-gq-bands 9 --gvcf-gq-bands 10 --gvcf-gq-bands 11 --gvcf-gq-bands 12 --gvcf-gq-bands 13 --gvcf-gq-bands 14 --gvcf-gq-bands 15 --gvcf-gq-bands 16 --gvcf-gq-bands 17 --gvcf-gq-bands 18 --gvcf-gq-bands 19 --gvcf-gq-bands 20 --gvcf-gq-bands 21 --gvcf-gq-bands 22 --gvcf-gq-bands 23 --gvcf-gq-bands 24 --gvcf-gq-bands 25 --gvcf-gq-bands 26 --gvcf-gq-bands 27 --gvcf-gq-bands 28 --gvcf-gq-bands 29 --gvcf-gq-bands 30 --gvcf-gq-bands 31 --gvcf-gq-bands 32 --gvcf-gq-bands 33 --gvcf-gq-bands 34 --gvcf-gq-bands 35 --gvcf-gq-bands 36 --gvcf-gq-bands 37 --gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47 --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --floor-blocks false --indel-size-to-eliminate-in-ref-model 10 --disable-optimizations false --dragen-mode false --apply-bqd false --apply-frd false --disable-spanning-event-genotyping false --transform-dragen-mapping-quality false --mapping-quality-threshold-for-genotyping 20 --max-effective-depth-adjustment-for-frd 0 --just-determine-active-regions false --dont-genotype false --do-not-run-physical-phasing false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --adaptive-pruning false --do-not-recover-dangling-branches false --recover-dangling-heads false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.001 --pruning-lod-threshold 2.302585092994046 --pruning-seeding-lod-threshold 9.210340371976184 --max-unpruned-variants 100 --disable-artificial-haplotype-recovery false --enable-legacy-graph-cycle-detection false --debug-assembly false --debug-graph-transformations false --capture-assembly-failure-bam false --num-matching-bases-in-dangling-end-to-recover -1 --error-correction-log-odds -Infinity --error-correct-reads false --kmer-length-for-read-error-correction 25 --min-observations-for-kmer-to-be-solid 20 --base-quality-score-threshold 18 --dragstr-het-hom-ratio 2 --dont-use-dragstr-pair-hmm-scores false --pair-hmm-gap-continuation-penalty 10 --expected-mismatch-rate-for-read-disqualification 0.02 --pair-hmm-implementation FASTEST_AVAILABLE --pcr-indel-model CONSERVATIVE --phred-scaled-global-read-mismapping-rate 45 --disable-symmetric-hmm-normalizing false --disable-cap-base-qualities-to-map-quality false --enable-dynamic-read-disqualification-for-genotyping false --dynamic-read-disqualification-threshold 1.0 --native-pair-hmm-threads 4 --native-pair-hmm-use-double-precision false --dont-use-soft-clipped-bases false --min-base-quality-score 10 --smith-waterman JAVA --max-mnp-distance 0 --force-call-filtered-alleles false --soft-clip-low-quality-ends false --allele-informative-reads-overlap-margin 2 --smith-waterman-dangling-end-match-value 25 --smith-waterman-dangling-end-mismatch-penalty -50 --smith-waterman-dangling-end-gap-open-penalty -110 --smith-waterman-dangling-end-gap-extend-penalty -6 --smith-waterman-haplotype-to-reference-match-value 200 --smith-waterman-haplotype-to-reference-mismatch-penalty -150 --smith-waterman-haplotype-to-reference-gap-open-penalty -260 --smith-waterman-haplotype-to-reference-gap-extend-penalty -11 --smith-waterman-read-to-haplotype-match-value 10 --smith-waterman-read-to-haplotype-mismatch-penalty -15 --smith-waterman-read-to-haplotype-gap-open-penalty -30 --smith-waterman-read-to-haplotype-gap-extend-penalty -5 --min-assembly-region-size 50 --max-assembly-region-size 300 --max-prob-propagation-distance 50 --force-active false --padding-around-indels 75 --padding-around-snps 20 --padding-around-strs 75 --max-extension-into-assembly-region-padding-legacy 25 --max-reads-per-alignment-start 50 --enable-legacy-assembly-region-trimming false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false --minimum-mapping-quality 20 --disable-tool-default-annotations false --enable-all-annotations false --allow-old-rms-mapping-quality-annotation-data false\",Version=\"4.2.6.1\",Date=\"August 23, 2022 at 3:23:59 AM HKT\">',\n",
       " '##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=\"GenotypeGVCFs --output PID21-055.gatk.g.vcf.gz --force-output-intervals PID21-055.HC.g.vcf.gz --variant PID21-055.HC.g.vcf.gz --reference /home/louisshe/shortVariantVCF/ref/ucsc.hg19.fasta --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --use-posteriors-to-calculate-qual false --dont-use-dragstr-priors false --use-new-qual-calculator true --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genotype-assignment-method USE_PLS_TO_ASSIGN --genomicsdb-max-alternate-alleles 50 --call-genotypes false --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --genomicsdb-use-gcs-hdfs-connector false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false --disable-tool-default-annotations false --enable-all-annotations false --allow-old-rms-mapping-quality-annotation-data false\",Version=\"4.2.6.1\",Date=\"August 29, 2022 2:09:07 PM HKT\">',\n",
       " '##GATKCommandLine=<ID=HaplotypeCaller,CommandLine=\"HaplotypeCaller --annotate-with-num-discovered-alleles true --sample-ploidy 11 --output-mode EMIT_ALL_CONFIDENT_SITES --kmer-size 41 --min-dangling-branch-length 2 --recover-all-dangling-branches true --max-num-haplotypes-in-population 1280 --min-pruning 1 --max-unpruned-variants 100 --debug-assembly true --graph-output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.realigned.graph --pair-hmm-implementation EXACT --phred-scaled-global-read-mismapping-rate 368 --enable-dynamic-read-disqualification-for-genotyping true --bam-output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.realigned.bam --bam-writer-type ALL_POSSIBLE_HAPLOTYPES --min-base-quality-score 15 --emit-ref-confidence GVCF --soft-clip-low-quality-ends true --allele-informative-reads-overlap-margin 5 --smith-waterman-haplotype-to-reference-mismatch-penalty -120 --smith-waterman-read-to-haplotype-mismatch-penalty -1 --smith-waterman-read-to-haplotype-gap-extend-penalty -3 --output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.HC.g.vcf.gz --min-assembly-region-size 20 --force-active true --assembly-region-padding 150 --max-reads-per-alignment-start 0 --intervals /paedyl01/disk1/yangyxt/indexed_genome/homologous_regions/ACTB_related_homo_regions/ACTB/ACTB.bed --interval-padding 1000 --input /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.bqsr.homorelated.only_ACTB.bam --reference /paedyl01/disk1/yangyxt/indexed_genome/homologous_regions/ACTB_related_homo_regions/ACTB/ucsc.hg19.ucsc.hg19.sub.ACTB.masked.fasta --create-output-bam-index true --verbosity DEBUG --disable-read-filter WellformedReadFilter --disable-read-filter GoodCigarReadFilter --disable-read-filter NotSecondaryAlignmentReadFilter --disable-read-filter PassesVendorQualityCheckReadFilter --disable-read-filter MappedReadFilter --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --annotation-group StandardHCAnnotation --use-posteriors-to-calculate-qual false --dont-use-dragstr-priors false --use-new-qual-calculator true --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --standard-min-confidence-threshold-for-calling 30.0 --max-alternate-alleles 6 --max-genotype-count 1024 --num-reference-samples-if-no-call 0 --genotype-assignment-method USE_PLS_TO_ASSIGN --contamination-fraction-to-filter 0.0 --all-site-pls false --gvcf-gq-bands 1 --gvcf-gq-bands 2 --gvcf-gq-bands 3 --gvcf-gq-bands 4 --gvcf-gq-bands 5 --gvcf-gq-bands 6 --gvcf-gq-bands 7 --gvcf-gq-bands 8 --gvcf-gq-bands 9 --gvcf-gq-bands 10 --gvcf-gq-bands 11 --gvcf-gq-bands 12 --gvcf-gq-bands 13 --gvcf-gq-bands 14 --gvcf-gq-bands 15 --gvcf-gq-bands 16 --gvcf-gq-bands 17 --gvcf-gq-bands 18 --gvcf-gq-bands 19 --gvcf-gq-bands 20 --gvcf-gq-bands 21 --gvcf-gq-bands 22 --gvcf-gq-bands 23 --gvcf-gq-bands 24 --gvcf-gq-bands 25 --gvcf-gq-bands 26 --gvcf-gq-bands 27 --gvcf-gq-bands 28 --gvcf-gq-bands 29 --gvcf-gq-bands 30 --gvcf-gq-bands 31 --gvcf-gq-bands 32 --gvcf-gq-bands 33 --gvcf-gq-bands 34 --gvcf-gq-bands 35 --gvcf-gq-bands 36 --gvcf-gq-bands 37 --gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47 --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --floor-blocks false --indel-size-to-eliminate-in-ref-model 10 --disable-optimizations false --dragen-mode false --apply-bqd false --apply-frd false --disable-spanning-event-genotyping false --transform-dragen-mapping-quality false --mapping-quality-threshold-for-genotyping 20 --max-effective-depth-adjustment-for-frd 0 --just-determine-active-regions false --dont-genotype false --do-not-run-physical-phasing false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --adaptive-pruning false --do-not-recover-dangling-branches false --recover-dangling-heads false --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 --adaptive-pruning-initial-error-rate 0.001 --pruning-lod-threshold 2.302585092994046 --pruning-seeding-lod-threshold 9.210340371976184 --linked-de-bruijn-graph false --disable-artificial-haplotype-recovery false --enable-legacy-graph-cycle-detection false --debug-graph-transformations false --capture-assembly-failure-bam false --num-matching-bases-in-dangling-end-to-recover -1 --error-correction-log-odds -Infinity --error-correct-reads false --kmer-length-for-read-error-correction 25 --min-observations-for-kmer-to-be-solid 20 --base-quality-score-threshold 18 --dragstr-het-hom-ratio 2 --dont-use-dragstr-pair-hmm-scores false --pair-hmm-gap-continuation-penalty 10 --expected-mismatch-rate-for-read-disqualification 0.02 --pcr-indel-model CONSERVATIVE --disable-symmetric-hmm-normalizing false --disable-cap-base-qualities-to-map-quality false --dynamic-read-disqualification-threshold 1.0 --native-pair-hmm-threads 4 --native-pair-hmm-use-double-precision false --dont-use-soft-clipped-bases false --smith-waterman JAVA --max-mnp-distance 0 --force-call-filtered-alleles false --smith-waterman-dangling-end-match-value 25 --smith-waterman-dangling-end-mismatch-penalty -50 --smith-waterman-dangling-end-gap-open-penalty -110 --smith-waterman-dangling-end-gap-extend-penalty -6 --smith-waterman-haplotype-to-reference-match-value 200 --smith-waterman-haplotype-to-reference-gap-open-penalty -260 --smith-waterman-haplotype-to-reference-gap-extend-penalty -11 --smith-waterman-read-to-haplotype-match-value 10 --smith-waterman-read-to-haplotype-gap-open-penalty -30 --max-assembly-region-size 300 --active-probability-threshold 0.002 --max-prob-propagation-distance 50 --padding-around-indels 75 --padding-around-snps 20 --padding-around-strs 75 --max-extension-into-assembly-region-padding-legacy 25 --enable-legacy-assembly-region-trimming false --interval-set-rule UNION --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false --minimum-mapping-quality 20 --disable-tool-default-annotations false --enable-all-annotations false --allow-old-rms-mapping-quality-annotation-data false\",Version=\"4.2.6.1\",Date=\"August 20, 2022 at 8:20:03 PM HKT\">',\n",
       " '##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=\"GenotypeGVCFs --output /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.vcf.gz --standard-min-confidence-threshold-for-calling 10.0 --force-output-intervals /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.HC.g.vcf.gz --variant /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.HC.g.vcf.gz --reference /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --annotation-group StandardAnnotation --annotation-group AS_StandardAnnotation --include-non-variant-sites false --merge-input-intervals false --input-is-somatic false --tumor-lod-to-emit 3.5 --allele-fraction-error 0.001 --keep-combined-raw-annotations false --use-posteriors-to-calculate-qual false --dont-use-dragstr-priors false --use-new-qual-calculator true --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 --max-alternate-alleles 6 --max-genotype-count 1024 --sample-ploidy 2 --num-reference-samples-if-no-call 0 --genotype-assignment-method USE_PLS_TO_ASSIGN --genomicsdb-max-alternate-alleles 50 --call-genotypes false --genomicsdb-use-bcf-codec false --genomicsdb-shared-posixfs-optimizations false --genomicsdb-use-gcs-hdfs-connector false --only-output-calls-starting-in-intervals false --interval-set-rule UNION --interval-padding 0 --interval-exclusion-padding 0 --interval-merging-rule ALL --read-validation-stringency SILENT --seconds-between-progress-updates 10.0 --disable-sequence-dictionary-validation false --create-output-bam-index true --create-output-bam-md5 false --create-output-variant-index true --create-output-variant-md5 false --max-variants-per-shard 0 --lenient false --add-output-sam-program-record true --add-output-vcf-command-line true --cloud-prefetch-buffer 40 --cloud-index-prefetch-buffer -1 --disable-bam-index-caching false --sites-only-vcf-output false --help false --version false --showHidden false --verbosity INFO --QUIET false --use-jdk-deflater false --use-jdk-inflater false --gcs-max-retries 20 --gcs-project-for-requester-pays  --disable-tool-default-read-filters false --disable-tool-default-annotations false --enable-all-annotations false --allow-old-rms-mapping-quality-annotation-data false\",Version=\"4.2.6.1\",Date=\"August 20, 2022 at 8:26:06 PM HKT\">',\n",
       " '##INFO=<ID=AS_RAW_ReadPosRankSum,Number=1,Type=String,Description=\"allele specific raw data for rank sum test of read position bias\">',\n",
       " '##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=\"Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed\">',\n",
       " '##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">',\n",
       " '##INFO=<ID=AS_RAW_BaseQRankSum,Number=1,Type=String,Description=\"raw data for allele specific rank sum test of base qualities\">',\n",
       " '##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\">',\n",
       " '##INFO=<ID=AS_MQ,Number=A,Type=Float,Description=\"Allele-specific RMS Mapping Quality\">',\n",
       " '##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\">',\n",
       " '##INFO=<ID=SOR,Number=1,Type=Float,Description=\"Symmetric Odds Ratio of 2x2 contingency table to detect strand bias\">',\n",
       " '##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\">',\n",
       " '##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=\"Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\">',\n",
       " '##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\">',\n",
       " '##INFO=<ID=NDA,Number=1,Type=Integer,Description=\"Number of alternate alleles discovered (but not necessarily genotyped) at this site\">',\n",
       " '##INFO=<ID=AS_SOR,Number=A,Type=Float,Description=\"Allele specific strand Odds Ratio of 2x|Alts| contingency table to detect allele specific strand bias\">',\n",
       " '##INFO=<ID=AS_InbreedingCoeff,Number=A,Type=Float,Description=\"Allele-specific inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation\">',\n",
       " '##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">',\n",
       " '##INFO=<ID=AS_ReadPosRankSum,Number=A,Type=Float,Description=\"allele specific Z-score from Wilcoxon rank sum test of each Alt vs. Ref read position bias\">',\n",
       " '##INFO=<ID=AS_RAW_MQ,Number=1,Type=String,Description=\"Allele-specfic raw data for RMS Mapping Quality\">',\n",
       " '##INFO=<ID=AS_BaseQRankSum,Number=A,Type=Float,Description=\"allele specific Z-score from Wilcoxon rank sum test of each Alt Vs. Ref base qualities\">',\n",
       " '##INFO=<ID=AS_MQRankSum,Number=A,Type=Float,Description=\"Allele-specific Mapping Quality Rank Sum\">',\n",
       " '##INFO=<ID=AS_SB_TABLE,Number=1,Type=String,Description=\"Allele-specific forward/reverse read counts for strand bias tests. Includes the reference and alleles separated by |.\">',\n",
       " '##INFO=<ID=END,Number=1,Type=Integer,Description=\"Stop position of the interval\">',\n",
       " '##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\">',\n",
       " '##INFO=<ID=FS,Number=1,Type=Float,Description=\"Phred-scaled p-value using Fisher\\'s exact test to detect strand bias\">',\n",
       " '##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=\"Phred-scaled p-value for exact test of excess heterozygosity\">',\n",
       " '##INFO=<ID=AS_FS,Number=A,Type=Float,Description=\"allele specific phred-scaled p-value using Fisher\\'s exact test to detect strand bias of each alt allele\">',\n",
       " '##INFO=<ID=MLEAF,Number=A,Type=Float,Description=\"Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed\">',\n",
       " '##INFO=<ID=AS_QD,Number=A,Type=Float,Description=\"Allele-specific Variant Confidence/Quality by Depth\">',\n",
       " '##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=\"Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation\">',\n",
       " '##INFO=<ID=QD,Number=1,Type=Float,Description=\"Variant Confidence/Quality by Depth\">',\n",
       " '##INFO=<ID=AS_RAW_MQRankSum,Number=1,Type=String,Description=\"Allele-specfic raw data for Mapping Quality Rank Sum\">',\n",
       " '##INFO=<ID=RAW_MQandDP,Number=2,Type=Integer,Description=\"Raw data (sum of squared MQ and total depth) for improved RMS Mapping Quality calculation. Incompatible with deprecated RAW_MQ formulation.\">',\n",
       " '##contig=<ID=chrUn_gl000246,length=38154>',\n",
       " '##contig=<ID=chr6_mcf_hap5,length=4833398>',\n",
       " '##contig=<ID=chr16,length=90354753>',\n",
       " '##contig=<ID=chr9_gl000199_random,length=169874>',\n",
       " '##contig=<ID=chrUn_gl000211,length=166566>',\n",
       " '##contig=<ID=chr6_dbb_hap3,length=4610396>',\n",
       " '##contig=<ID=chrY,length=59373566>',\n",
       " '##contig=<ID=chrUn_gl000228,length=129120>',\n",
       " '##contig=<ID=chr6,length=171115067>',\n",
       " '##contig=<ID=chr1_gl000192_random,length=547496>',\n",
       " '##contig=<ID=chr20,length=63025520>',\n",
       " '##contig=<ID=chr17_gl000206_random,length=41001>',\n",
       " '##contig=<ID=chr19_gl000208_random,length=92689>',\n",
       " '##contig=<ID=chr7_gl000195_random,length=182896>',\n",
       " '##contig=<ID=chrUn_gl000218,length=161147>',\n",
       " '##contig=<ID=chrUn_gl000245,length=36651>',\n",
       " '##contig=<ID=chr9_gl000201_random,length=36148>',\n",
       " '##contig=<ID=chr18,length=78077248>',\n",
       " '##contig=<ID=chrUn_gl000212,length=186858>',\n",
       " '##contig=<ID=chrUn_gl000247,length=36422>',\n",
       " '##contig=<ID=chr6_qbl_hap6,length=4611984>',\n",
       " '##contig=<ID=chrUn_gl000223,length=180455>',\n",
       " '##contig=<ID=chrUn_gl000240,length=41933>',\n",
       " '##contig=<ID=chrUn_gl000231,length=27386>',\n",
       " '##contig=<ID=chrUn_gl000236,length=41934>',\n",
       " '##contig=<ID=chr19_gl000209_random,length=159169>',\n",
       " '##contig=<ID=chrUn_gl000237,length=45867>',\n",
       " '##contig=<ID=chr14,length=107349540>',\n",
       " '##contig=<ID=chrUn_gl000219,length=179198>',\n",
       " '##contig=<ID=chr15,length=102531392>',\n",
       " '##contig=<ID=chr4_gl000194_random,length=191469>',\n",
       " '##contig=<ID=chrUn_gl000222,length=186861>',\n",
       " '##contig=<ID=chr4_gl000193_random,length=189789>',\n",
       " '##contig=<ID=chrUn_gl000225,length=211173>',\n",
       " '##contig=<ID=chrUn_gl000248,length=39786>',\n",
       " '##contig=<ID=chr21_gl000210_random,length=27682>',\n",
       " '##contig=<ID=chrUn_gl000242,length=43523>',\n",
       " '##contig=<ID=chr17_gl000203_random,length=37498>',\n",
       " '##contig=<ID=chr3,length=198022430>',\n",
       " '##contig=<ID=chr22,length=51304566>',\n",
       " '##contig=<ID=chrUn_gl000229,length=19913>',\n",
       " '##contig=<ID=chrUn_gl000213,length=164239>',\n",
       " '##contig=<ID=chr4,length=191154276>',\n",
       " '##contig=<ID=chr7,length=159138663>',\n",
       " '##contig=<ID=chr17_gl000204_random,length=81310>',\n",
       " '##contig=<ID=chrUn_gl000238,length=39939>',\n",
       " '##contig=<ID=chr17_gl000205_random,length=174588>',\n",
       " '##contig=<ID=chrUn_gl000220,length=161802>',\n",
       " '##contig=<ID=chr18_gl000207_random,length=4262>',\n",
       " '##contig=<ID=chrUn_gl000224,length=179693>',\n",
       " '##contig=<ID=chr5,length=180915260>',\n",
       " '##contig=<ID=chrUn_gl000214,length=137718>',\n",
       " '##contig=<ID=chrUn_gl000227,length=128374>',\n",
       " '##contig=<ID=chr21,length=48129895>',\n",
       " '##contig=<ID=chr17,length=81195210>',\n",
       " '##contig=<ID=chr1_gl000191_random,length=106433>',\n",
       " '##contig=<ID=chr10,length=135534747>',\n",
       " '##contig=<ID=chr8_gl000196_random,length=38914>',\n",
       " '##contig=<ID=chrM,length=16571>',\n",
       " '##contig=<ID=chr12,length=133851895>',\n",
       " '##contig=<ID=chr17_ctg5_hap1,length=1680828>',\n",
       " '##contig=<ID=chrUn_gl000221,length=155397>',\n",
       " '##contig=<ID=chrUn_gl000243,length=43341>',\n",
       " '##contig=<ID=chr6_cox_hap2,length=4795371>',\n",
       " '##contig=<ID=chrUn_gl000239,length=33824>',\n",
       " '##contig=<ID=chr11,length=135006516>',\n",
       " '##contig=<ID=chr8_gl000197_random,length=37175>',\n",
       " '##contig=<ID=chr4_ctg9_hap1,length=590426>',\n",
       " '##contig=<ID=chr1,length=249250621>',\n",
       " '##contig=<ID=chrUn_gl000249,length=38502>',\n",
       " '##contig=<ID=chr9_gl000200_random,length=187035>',\n",
       " '##contig=<ID=chr9_gl000198_random,length=90085>',\n",
       " '##contig=<ID=chrUn_gl000217,length=172149>',\n",
       " '##contig=<ID=chr13,length=115169878>',\n",
       " '##contig=<ID=chrUn_gl000216,length=172294>',\n",
       " '##contig=<ID=chr9,length=141213431>',\n",
       " '##contig=<ID=chrUn_gl000233,length=45941>',\n",
       " '##contig=<ID=chrUn_gl000232,length=40652>',\n",
       " '##contig=<ID=chrX,length=155270560>',\n",
       " '##contig=<ID=chrUn_gl000215,length=172545>',\n",
       " '##contig=<ID=chr2,length=243199373>',\n",
       " '##contig=<ID=chrUn_gl000241,length=42152>',\n",
       " '##contig=<ID=chr11_gl000202_random,length=40103>',\n",
       " '##contig=<ID=chr8,length=146364022>',\n",
       " '##contig=<ID=chr19,length=59128983>',\n",
       " '##contig=<ID=chrUn_gl000234,length=40531>',\n",
       " '##contig=<ID=chrUn_gl000244,length=39929>',\n",
       " '##contig=<ID=chr6_ssto_hap7,length=4928567>',\n",
       " '##contig=<ID=chr6_apd_hap1,length=4622290>',\n",
       " '##contig=<ID=chrUn_gl000230,length=43691>',\n",
       " '##contig=<ID=chrUn_gl000226,length=15008>',\n",
       " '##contig=<ID=chrUn_gl000235,length=34474>',\n",
       " '##contig=<ID=chr6_mann_hap4,length=4683263>',\n",
       " '##source=GenotypeGVCFs',\n",
       " '##source=HaplotypeCaller',\n",
       " '##bcftools_filterVersion=1.11+htslib-1.11',\n",
       " '##bcftools_filterVersion=1.15.1+htslib-1.15',\n",
       " '##bcftools_filterCommand=filter -r chr13 -Oz -o PID21-055.gatk.g.vcf.gz.chr13 PID21-055.gatk.g.vcf.gz; Date=Tue Aug 30 13:37:44 2022',\n",
       " \"##bcftools_filterCommand=filter -e 'FORMAT/DP[0] == 0' -Oz -o /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.tmp.vcf.gz /paedyl01/disk1/yangyxt/wesplus/150_samples_20220315/aligned_results/PID21-055.only_ACTB.vcf.gz; Date=Sat Aug 20 20:26:07 2022\",\n",
       " '##reference=file:///paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ov_header, ov_subjects, ov_df = loadVCF(ov_vcf)\n",
    "pv_header, pv_subjects = loadVCF(pv_vcf, omit_record=True)\n",
    "\n",
    "# Add filters for GATK and SDrecall (pv_tag and ov_tag)\n",
    "\n",
    "\n",
    "\n",
    "ov_filter_head = f\"##FILTER=<ID={ov_tag},Description='variants called from {ov_tag}'>\"\n",
    "pv_filter_head = f\"##FILTER=<ID={pv_tag},Description='variants called from {pv_tag}'>\"\n",
    "ov_header.append(ov_filter_head)\n",
    "ov_header.append(pv_filter_head)\n",
    "merged_header = concat_headers(pv_header, ov_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3a3e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID21-055\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def printRow(row):\n",
    "    \n",
    "    print(row.index[9])\n",
    "#     var = Variant(row, row.name)\n",
    "#     print(\":\".join(var.SAMPLE.values()))\n",
    "#     print(\";\".join([f\"{key}={value[0]}\" for key, value in var._INFO.items()]))\n",
    "#     print(var._INFO.keys())\n",
    "#     print(Variant(row, row.name).getSeries())\n",
    "#     print(type(row))\n",
    "    sys.exit()\n",
    "ov_df.apply(printRow, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "547352e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrorder = [\"chrM\", \"chr1\", \"chr2\", \"chr3\", \"chr4\", \"chr5\", \"chr6\", \"chr7\", \"chr8\", \"chr9\", \"chr10\", \n",
    "                         \"chr11\", \"chr12\", \"chr13\", \"chr14\", \"chr15\", \"chr16\", \"chr17\", \"chr18\", \"chr19\", \"chr20\", \n",
    "                         \"chr21\", \"chr22\", \"chrX\", \"chrY\", \"chr1_gl000191_random\", \"chr1_gl000192_random\", \n",
    "                         \"chr4_ctg9_hap1\", \"chr4_gl000193_random\", \"chr4_gl000194_random\", \n",
    "                         \"chr6_apd_hap1\", \"chr6_cox_hap2\", \"chr6_dbb_hap3\", \"chr6_mann_hap4\", \"chr6_mcf_hap5\", \"chr6_qbl_hap6\", \"chr6_ssto_hap7\", \n",
    "                         \"chr7_gl000195_random\", \"chr8_gl000196_random\", \"chr8_gl000197_random\", \n",
    "                         \"chr9_gl000198_random\", \"chr9_gl000199_random\", \"chr9_gl000200_random\", \"chr9_gl000201_random\", \n",
    "                         \"chr11_gl000202_random\", \"chr17_ctg5_hap1\", \n",
    "                         \"chr17_gl000203_random\", \"chr17_gl000204_random\", \"chr17_gl000205_random\", \"chr17_gl000206_random\", \n",
    "                         \"chr18_gl000207_random\", \"chr19_gl000208_random\", \"chr19_gl000209_random\", \"chr21_gl000210_random\", \n",
    "                         \"chrUn_gl000211\", \"chrUn_gl000212\", \"chrUn_gl000213\", \"chrUn_gl000214\", \"chrUn_gl000215\", \"chrUn_gl000216\", \n",
    "                         \"chrUn_gl000217\", \"chrUn_gl000218\", \"chrUn_gl000219\", \"chrUn_gl000220\", \"chrUn_gl000221\", \"chrUn_gl000222\", \n",
    "                         \"chrUn_gl000223\", \"chrUn_gl000224\", \"chrUn_gl000225\", \"chrUn_gl000226\", \"chrUn_gl000227\", \"chrUn_gl000228\", \n",
    "                         \"chrUn_gl000229\", \"chrUn_gl000230\", \"chrUn_gl000231\", \"chrUn_gl000232\", \"chrUn_gl000233\", \"chrUn_gl000234\", \n",
    "                         \"chrUn_gl000235\", \"chrUn_gl000236\", \"chrUn_gl000237\", \"chrUn_gl000238\", \"chrUn_gl000239\", \"chrUn_gl000240\", \n",
    "                         \"chrUn_gl000241\", \"chrUn_gl000242\", \"chrUn_gl000243\", \"chrUn_gl000244\", \"chrUn_gl000245\", \"chrUn_gl000246\", \n",
    "                         \"chrUn_gl000247\", \"chrUn_gl000248\", \"chrUn_gl000249\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7b967c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrM\n"
     ]
    }
   ],
   "source": [
    "class Chromosome:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.GRCh37 = (self.name.lower().startswith(\"chr\"))\n",
    "        self.length = len(self.name)\n",
    "        self.contig = self.name[3:] if self.GRCh37 else self.name\n",
    "        \n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Hash function for self.contig (eg. M, 1, 2, ..., Un_gl000248)\n",
    "        \"\"\"\n",
    "        contig_map = {\n",
    "                       \"M\": 48,  \"1\": 49,  \"2\": 50,  \"3\": 51,  \"4\": 52,  \"5\": 53,  \"6\": 54,  \"7\": 55,\n",
    "                       \"8\": 56,  \"9\": 57, \"10\": 58, \"11\": 59, \"12\": 60, \"13\": 61, \"14\": 62, \"15\": 63,\n",
    "                      \"16\": 64, \"17\": 65, \"18\": 66, \"19\": 67, \"20\": 68, \"21\": 69, \"22\": 70,  \"X\": 71,\n",
    "                       \"Y\": 72, \"Un\": 73\n",
    "                     }\n",
    "        key = contig_map.get(self.contig.split(\"_\")[0], 74)\n",
    "        if self.contig.split(\"_\")[1:]:\n",
    "            return key * self.length * sum(ord(letter) for letter in \"_\".join(self.contig.split(\"_\")[1:]))\n",
    "        else:\n",
    "            return key * self.length * 1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.__hash__() < other.__hash__()\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.__hash__() > other.__hash__()\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.__hash__() <= other.__hash__()\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self.__hash__() >= other.__hash__()\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.__hash__() == other.__hash__()\n",
    "    \n",
    "test = Chromosome(\"chrM\")\n",
    "test2 = Chromosome(\"chr1\")\n",
    "test == test\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e232e",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "- [ ] merge_vcf_heads\n",
    "- [ ] pick_rep_rec\n",
    "- [ ] main_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5f5e40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[chrM,\n",
       " chr1,\n",
       " chr2,\n",
       " chr3,\n",
       " chr4,\n",
       " chr5,\n",
       " chr6,\n",
       " chr7,\n",
       " chr8,\n",
       " chr9,\n",
       " chrX,\n",
       " chrY,\n",
       " chr10,\n",
       " chr11,\n",
       " chr12,\n",
       " chr13,\n",
       " chr14,\n",
       " chr15,\n",
       " chr16,\n",
       " chr17,\n",
       " chr18,\n",
       " chr19,\n",
       " chr20,\n",
       " chr21,\n",
       " chr22,\n",
       " chrUn_gl000211,\n",
       " chrUn_gl000220,\n",
       " chrUn_gl000212,\n",
       " chrUn_gl000221,\n",
       " chrUn_gl000230,\n",
       " chrUn_gl000213,\n",
       " chrUn_gl000222,\n",
       " chrUn_gl000231,\n",
       " chrUn_gl000240,\n",
       " chrUn_gl000214,\n",
       " chrUn_gl000223,\n",
       " chrUn_gl000232,\n",
       " chrUn_gl000241,\n",
       " chrUn_gl000215,\n",
       " chrUn_gl000224,\n",
       " chrUn_gl000233,\n",
       " chrUn_gl000242,\n",
       " chrUn_gl000216,\n",
       " chrUn_gl000225,\n",
       " chrUn_gl000234,\n",
       " chrUn_gl000243,\n",
       " chrUn_gl000217,\n",
       " chrUn_gl000226,\n",
       " chrUn_gl000235,\n",
       " chrUn_gl000244,\n",
       " chrUn_gl000218,\n",
       " chrUn_gl000227,\n",
       " chrUn_gl000236,\n",
       " chrUn_gl000245,\n",
       " chrUn_gl000219,\n",
       " chrUn_gl000228,\n",
       " chrUn_gl000237,\n",
       " chrUn_gl000246,\n",
       " chrUn_gl000229,\n",
       " chrUn_gl000238,\n",
       " chrUn_gl000247,\n",
       " chrUn_gl000239,\n",
       " chrUn_gl000248,\n",
       " chrUn_gl000249,\n",
       " chr6_dbb_hap3,\n",
       " chr6_apd_hap1,\n",
       " chr6_mcf_hap5,\n",
       " chr6_qbl_hap6,\n",
       " chr6_cox_hap2,\n",
       " chr4_ctg9_hap1,\n",
       " chr6_mann_hap4,\n",
       " chr6_ssto_hap7,\n",
       " chr17_ctg5_hap1,\n",
       " chr1_gl000191_random,\n",
       " chr1_gl000192_random,\n",
       " chr4_gl000193_random,\n",
       " chr4_gl000194_random,\n",
       " chr7_gl000195_random,\n",
       " chr8_gl000196_random,\n",
       " chr8_gl000197_random,\n",
       " chr9_gl000200_random,\n",
       " chr9_gl000201_random,\n",
       " chr9_gl000198_random,\n",
       " chr9_gl000199_random,\n",
       " chr11_gl000202_random,\n",
       " chr17_gl000203_random,\n",
       " chr17_gl000204_random,\n",
       " chr17_gl000205_random,\n",
       " chr17_gl000206_random,\n",
       " chr18_gl000207_random,\n",
       " chr19_gl000208_random,\n",
       " chr19_gl000209_random,\n",
       " chr21_gl000210_random]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_cls = [ Chromosome(chrom) for chrom in chrorder ]\n",
    "sorted(chrom_cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

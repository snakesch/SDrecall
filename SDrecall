#!/usr/bin/env python3
"""
SDrecall - Main script for SDrecall workflow

This script provides a unified interface to run the complete SDrecall workflow
or individual stages of preparation and variant calling.
"""

import os
import sys
import argparse

from src.const import SDrecallPaths
from src.log import logger, configure_logger
from src.merge_variants_with_priority import merge_with_priority

from prepare_recall_regions import prepare_recall_regions
from realign_and_recall import SDrecall_per_sample


# Add this new function to set thread limits based on user input
def set_numerical_thread_limits(threads):
    """
    Set thread limits for numerical libraries based on user-specified thread count
    
    Args:
        threads: Number of threads requested by user
    """
    # Set environment variables
    os.environ["OMP_NUM_THREADS"] = str(threads)
    os.environ["OPENBLAS_NUM_THREADS"] = str(threads)
    os.environ["MKL_NUM_THREADS"] = str(threads)
    os.environ["VECLIB_MAXIMUM_THREADS"] = str(threads)
    os.environ["NUMEXPR_NUM_THREADS"] = str(threads)
    
    logger.info(f"Numerical library thread limits set to {threads}")


def post_process_vcf(sdrecall_vcf, args):
    """
    Process the final VCF - potentially merging with conventional VCF
    
    Args:
        sdrecall_vcf: Path to SDrecall VCF
        args: Command line arguments
    
    Returns:
        Path to final VCF file
    """
    final_vcf = sdrecall_vcf
    
    # First, annotate with cohort VCF if provided
    if hasattr(args, 'cohort_vcf') and args.cohort_vcf:
        logger.info(f"Annotating with cohort VCF: {args.cohort_vcf}")
        
        # Create temporary output path for the annotated VCF
        from src.utils import prepare_tmp_file
        annotated_vcf = prepare_tmp_file(suffix='.vcf.gz').name
        
        # Run annotate_inhouse_common
        from identify_common_vars import annotate_inhouse_common
        annotated_vcf = annotate_inhouse_common(
            query_vcf=sdrecall_vcf,
            cohort_vcf=args.cohort_vcf,
            output_vcf=annotated_vcf,
            ref_genome=args.ref_genome,
            inhouse_common_cutoff=args.inhouse_common_cutoff,
            conf_level=args.cohort_conf_level,
            threads=args.threads
        )
        
        # Update the final_vcf to be the annotated one
        final_vcf = annotated_vcf
        logger.info(f"Variants annotated with inhouse_common filter: {final_vcf}")
    
    # Then, merge with conventional VCF if provided
    if hasattr(args, 'conventional_vcf') and args.conventional_vcf:
        logger.info(f"Merging with conventional VCF: {args.conventional_vcf}")
        
        # Determine output path for merged VCF
        if hasattr(args, 'merged_vcf') and args.merged_vcf:
            merged_vcf = args.merged_vcf
        else:
            # Derive from conventional VCF path
            merged_vcf = args.conventional_vcf.replace('.vcf.gz', '.sdrecall.vcf.gz')
            
        logger.info(f"Merged VCF will be written to: {merged_vcf}, from {final_vcf} and {args.conventional_vcf}")
        
        merge_with_priority(
            query_vcf=final_vcf,
            reference_vcf=args.conventional_vcf,
            output_vcf=merged_vcf,
            added_filter=None,
            qv_tag="SDrecall",
            rv_tag=args.caller_name,
            ref_genome=args.ref_genome,
            threads=args.threads
        )
        
        # Update the final VCF to be the merged one
        final_vcf = merged_vcf
        logger.info(f"Merged with conventional VCF: {final_vcf}")
    
    return final_vcf


def run_full_pipeline(args):
    """
    Run the complete SDrecall pipeline from preparation to variant calling
    
    Args:
        args: Command line arguments
    
    Returns:
        Path to the final recalled VCF file, possibly merged with conventional VCF
    """
    # Set thread limits based on user input
    set_numerical_thread_limits(args.threads)
    
    # Initialize paths
    paths = SDrecallPaths.initialize(
        ref_genome=args.ref_genome,
        input_bam=args.input_bam,
        reference_sd_map=args.reference_sd_map,
        output_dir=args.outdir,
        target_bed=args.target_bed,
        sample_id=args.sample_id,
        target_tag=args.target_tag
    )
    
    # Log key configuration
    logger.info(f"Running SDrecall pipeline with:")
    logger.info(f"  Sample ID: {paths.sample_id}")
    logger.info(f"  Assembly: {paths.assembly}")
    logger.info(f"  Target tag: {paths.target_tag}")
    logger.info(f"  Target BED: {paths.target_bed}")
    logger.info(f"  Input BAM: {paths.input_bam}")
    logger.info(f"  Working directory: {paths.work_dir}")
    
    # Preparation phase
    logger.info(f"Starting preparation phase, calling function prepare_recall_regions(paths={paths}, mq_threshold={args.mq_cutoff}, high_quality_depth={args.high_quality_depth}, minimum_depth={args.minimum_depth}, multialign_frac={args.multialign_frac}, threads={args.threads})")
    paths = prepare_recall_regions(
        paths=paths,
        mq_threshold=args.mq_cutoff,
        high_quality_depth=args.high_quality_depth,
        minimum_depth=args.minimum_depth,
        multialign_frac=args.multialign_frac,
        threads=args.threads
    )
    
    # Realignment and recall phase
    logger.info(f"Starting realignment and recall phase, calling function SDrecall_per_sample(sdrecall_paths={paths}, threads={args.threads}, numba_threads={args.numba_threads}, mq_cutoff={args.mq_cutoff}, conf_level={args.conf_level})")
    sdrecall_vcf = SDrecall_per_sample(
        sdrecall_paths=paths,
        threads=args.threads,
        numba_threads=args.numba_threads,
        mq_cutoff=args.mq_cutoff,
        conf_level=args.conf_level
    )
    
    logger.info(f"SDrecall pipeline completed successfully")
    logger.info(f"Final recalled variants: {sdrecall_vcf}")
    
    # Process and return final VCF
    return post_process_vcf(sdrecall_vcf, args)


def run_preparation_only(args):
    """
    Run only the preparation phase of SDrecall
    
    Args:
        args: Command line arguments
    
    Returns:
        Initialized SDrecallPaths instance
    """
    # Set thread limits based on user input
    set_numerical_thread_limits(args.threads)
    
    # Initialize paths
    paths = SDrecallPaths.initialize(
        ref_genome=args.ref_genome,
        input_bam=args.input_bam,
        reference_sd_map=args.reference_sd_map,
        output_dir=args.outdir,
        target_bed=args.target_bed,
        sample_id=args.sample_id,
        target_tag=args.target_tag
    )
    
    # Log key configuration
    logger.info(f"Running preparation phase only with:")
    logger.info(f"  Sample ID: {paths.sample_id}")
    logger.info(f"  Assembly: {paths.assembly}")
    logger.info(f"  Target tag: {paths.target_tag}")
    logger.info(f"  Target BED: {paths.target_bed}")
    logger.info(f"  Input BAM: {paths.input_bam}")
    logger.info(f"  Working directory: {paths.work_dir}")
    
    # Preparation phase
    paths = prepare_recall_regions(
        paths=paths,
        mq_threshold=args.mq_cutoff,
        high_quality_depth=args.high_quality_depth,
        minimum_depth=args.minimum_depth,
        multialign_frac=args.multialign_frac,
        threads=args.threads
    )
    
    logger.info(f"Preparation phase completed successfully")
    return paths


def run_realign_only(args):
    """
    Run only the realignment and recall phase of SDrecall
    
    Args:
        args: Command line arguments
    
    Returns:
        Path to the final recalled VCF file, possibly merged with conventional VCF
    """
    # Set thread limits based on user input
    set_numerical_thread_limits(args.threads)
    
    # Initialize paths without running preparation
    paths = SDrecallPaths.initialize(
        ref_genome=args.ref_genome,
        input_bam=args.input_bam,
        reference_sd_map=args.reference_sd_map,
        output_dir=args.outdir,
        target_bed=args.target_bed,
        sample_id=args.sample_id,
        target_tag=args.target_tag,
        clean_dirs=False
    )
    
    # Verify that preparation has been done
    if not os.path.exists(paths.multiplex_graph_path()):
        logger.error(f"Preparation has not been completed. Please run the preparation step first.")
        sys.exit(1)
    
    # Log configuration
    logger.info(f"Running SDrecall realignment with:")
    logger.info(f"  Sample ID: {paths.sample_id}")
    logger.info(f"  Input BAM: {paths.input_bam}")
    logger.info(f"  Assembly: {paths.assembly}")
    logger.info(f"  Working directory: {paths.work_dir}")
    
    # Run realignment and recall
    logger.info("Starting realignment and recall phase")
    sdrecall_vcf = SDrecall_per_sample(
        sdrecall_paths=paths,
        threads=args.threads,
        numba_threads=args.numba_threads,
        mq_cutoff=args.mq_cutoff,
        conf_level=args.conf_level
    )
    
    logger.info(f"SDrecall realignment and recall completed successfully")
    logger.info(f"Final recalled variants: {sdrecall_vcf}")
    
    # Process and return final VCF
    return post_process_vcf(sdrecall_vcf, args)


def main():
    """Main entry point for SDrecall"""
    
    # Create the top-level parser
    parser = argparse.ArgumentParser(
        description='SDrecall - Complement SNV and small Indel detection within Segmental Duplication based on NGS data',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # Add global arguments
    parser.add_argument('-v', '--verbose', type=str, default="INFO", 
                        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                        help='Logging verbosity level')
    
    # Create subparsers for different modes
    subparsers = parser.add_subparsers(dest='mode', help='Operation mode')
    
    # Full pipeline mode
    full_parser = subparsers.add_parser('run', help='Run the complete SDrecall pipeline')
    _add_common_args(full_parser)
    _add_preparation_args(full_parser)
    _add_realignment_args(full_parser)
    _add_conventional_vcf_args(full_parser)
    _add_cohort_args(full_parser)
    full_parser.set_defaults(func=run_full_pipeline)
    
    # Preparation only mode
    prep_parser = subparsers.add_parser('prepare', help='Run only the preparation phase')
    _add_common_args(prep_parser)
    _add_preparation_args(prep_parser)
    prep_parser.set_defaults(func=run_preparation_only)
    
    # Realignment only mode
    realign_parser = subparsers.add_parser('realign', help='Run only the realignment and recall phase')
    _add_common_args(realign_parser)
    _add_realignment_args(realign_parser)
    _add_conventional_vcf_args(realign_parser)
    _add_cohort_args(realign_parser)
    realign_parser.set_defaults(func=run_realign_only)
    
    # Parse arguments
    args = parser.parse_args()

    # Check if the reference genome file name suffix is .fasta
    if not args.ref_genome.endswith('.fasta'):
        logger.error(f"Reference genome file name suffix has to be .fasta, but {args.ref_genome} is not.")
        sys.exit(1)
    
    # Configure logging
    configure_logger(log_level=args.verbose)
    
    # If no mode is specified, print help and exit
    if not hasattr(args, 'func'):
        parser.print_help()
        sys.exit(1)
    
    # Run the selected mode
    final_vcf = args.func(args)
    
    if final_vcf:
        logger.info(f"Final output: {final_vcf}")


def _add_common_args(parser):
    """Add common arguments shared by multiple modes"""
    parser.add_argument('-r', '--ref_genome', required=True, 
                        help='Path to the reference genome FASTA file (hg19 or hg38), file name suffix has to be .fasta')
    parser.add_argument('-o', '--outdir', required=True, 
                        help='Base directory for output files')
    parser.add_argument('-i', '--input_bam', required=True, 
                        help='Input BAM file')
    parser.add_argument('-m', '--reference_sd_map', required=True, 
                        help='Reference SD map file')
    parser.add_argument('-b', '--target_bed', required=True, 
                        help='Target BED file')
    parser.add_argument('-s', '--sample_id', default=None, 
                        help='Sample ID (extracted from BAM filename if not provided)')
    parser.add_argument('--target_tag', type=str, default="exome", 
                        help='Target region tag')
    parser.add_argument('-t', '--threads', type=int, default=10, 
                        help='Number of threads to use')
    parser.add_argument('--mq_cutoff', type=int, default=41, 
                        help='Mapping quality cutoff')


def _add_preparation_args(parser):
    """Add arguments specific to the preparation phase"""
    parser.add_argument('--high_quality_depth', type=int, default=10, 
                        help='High quality depth cutoff')
    parser.add_argument('--minimum_depth', type=int, default=3, 
                        help='Minimum depth cutoff')
    parser.add_argument('--multialign_frac', type=float, default=0.5, 
                        help='Multi-align fraction cutoff')


def _add_realignment_args(parser):
    """Add arguments specific to the realignment phase"""
    parser.add_argument('--numba_threads', type=int, default=4, 
                        help='Number of threads for numba acceleration')
    parser.add_argument('--conf_level', type=float, default=0.01, 
                        help='Confidence level for statistical tests')


def _add_conventional_vcf_args(parser):
    """Add arguments for conventional VCF merging"""
    parser.add_argument('--conventional_vcf', type=str, default=None,
                        help='Path to a VCF file from a conventional caller (e.g., GATK, DeepVariant)')
    parser.add_argument('--caller_name', type=str, default='conventional',
                        help='Name of the conventional caller (e.g., GATK, DeepVariant)')
    parser.add_argument('--merged_vcf', type=str, default=None,
                        help='Path for the merged output VCF (default: derived from conventional_vcf path)')


def _add_cohort_args(parser):
    """Add arguments for cohort VCF annotation"""
    parser.add_argument('--cohort_vcf', type=str, default=None,
                        help='Path to a cohort-level VCF with control samples')
    parser.add_argument('--inhouse_common_cutoff', type=float, default=0.01,
                        help='Frequency cutoff for common variants in cohort')
    parser.add_argument('--cohort_conf_level', type=float, default=0.999,
                        help='Confidence level threshold for common variant determination')


if __name__ == "__main__":
    main()
